# Configuration parameters for training (loss, optimizer, lr, datasets)
training_config:
  debug_run: false # IMPORTANT set to false for real training
  checkpoint_path_prefix: 'results'
  load_previous_train_state: true
  epochs: 100
  dataset:
    sequence_path_prefix: 'datasets/AIC20/'
    sequences_train: 
      - 'S01'
      - 'S04'
      - 'S03'
    sequences_val: 
      - 'S02'
    annotations_filename: 'gt.txt'
    num_ids_per_graph: 64
    embeddings_per_iteration: 512
    resized_img_shape: [384,384]
    train_batch_size: 1
    test_batch_size: 1
    negative_sampling: false # Negative sampling to balance training
  loss:
    loss_type: 'ce_custom' # 'ce' - 'focal' - 'bce'
    alpha: [0.25, 0.75]
    gamma: 2
  lr_scheduler:
    toggle: off
    scheduler_type: 'step' 
    step_size: 50
    gamma: 0.1
    warmup_duration: 5
  optimizer:
    lr: 0.01
    momentum: 0.9
    dampening: 0
  reid:
    reid_model_path: 'models/reid/resnet101_ibn_a_2.pth'

# Configuration parameters for the GNN architecture
gnn_arch:
  node_agg_fn: 'sum'
  num_enc_steps: 1  
  num_class_steps: 1 
  reattach_initial_nodes: False  
  reattach_initial_edges: False 

  gallery_combinator: # To disable, replace the dictionary with off value.
    layer: gru
    combinator_feature_size: 2048 # dimension of every vector in gallery
    combinator_output_size: 2048 # Dimension of the resulting embedding
    frames_per_gallery: 20
    combinator_num_gru_layers: 1

  encoder_feats_dict:
    edges:
      edge_in_dim: 2 
      edge_fc_dims: [4] 
      edge_out_dim: 4 

    nodes:
      node_in_dim: 2048
      node_fc_dims: [1024,512, 128]
      node_out_dim: 32
      dropout_p: 0.1
      use_batchnorm: True

  # MPN edge update
  edge_model_feats_dict:
    fc_dims: [4] 
    dropout_p: 0.1
    use_batchnorm: True

  # MPN node update
  node_model_feats_dict:
    fc_dims: [32]  
    dropout_p: 0.1
    use_batchnorm: True

  # Classifier
  classifier_feats_dict:
    edge_in_dim: 4 
    edge_fc_dims: [] 
    edge_out_dim: 2
    dropout_p: 0
    use_batchnorm: False
    is_classifier: True