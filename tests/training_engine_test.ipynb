{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "sys.path.insert(1, osp.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "dataset1 = datasets.MNIST('mnist', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('mnist', train=False,\n",
    "                    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import NLLLoss\n",
    "\n",
    "model = Net()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.1)\n",
    "criterion = NLLLoss()\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.995)\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_trainer.trainer_abstract import TrainingEngineAbstract\n",
    "class TrainingEngine(TrainingEngineAbstract):\n",
    "    def setup_train_step(self):\n",
    "        def train_step(engine, batch):\n",
    "            self.gnn_model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            x, y = batch[0].to(device), batch[1].to(device)\n",
    "            y_pred = self.gnn_model(x)\n",
    "            loss = self.loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            return loss.item()\n",
    "        return train_step\n",
    "    \n",
    "    def setup_validation_step(self):\n",
    "        def validation_step(engine, batch):\n",
    "            self.gnn_model.eval()\n",
    "            with torch.no_grad():\n",
    "                x, y = batch[0].to(device), batch[1].to(device)\n",
    "                y_pred = self.gnn_model(x)\n",
    "                return y_pred, y\n",
    "        return validation_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(dataset1, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset2, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. TrainingEngine instantiated.\n",
      "9. Added training function to TrainingEngine.\n",
      "10. Added metrics to TrainingEngine.\n",
      "11. Added Loggers to TrainingEngine.\n",
      "12. Added Checkpointer to TrainingEngine.\n",
      "14. Tensorboard enabled.\n",
      "Epoch[1], Iter[100] Loss: 0.52\n",
      "Epoch[1], Iter[200] Loss: 0.33\n",
      "Epoch[1], Iter[300] Loss: 0.30\n",
      "Epoch[1], Iter[400] Loss: 0.28\n",
      "Epoch[1], Iter[500] Loss: 0.30\n",
      "Epoch[1], Iter[600] Loss: 0.19\n",
      "Epoch[1], Iter[700] Loss: 0.21\n",
      "Epoch[1], Iter[800] Loss: 0.07\n",
      "Epoch[1], Iter[900] Loss: 0.19\n",
      "Train Results - Epoch[1] - Accuracy: 0.97545 - Precision: tensor([0.9915, 0.9821, 0.9773, 0.9733, 0.9789, 0.9680, 0.9767, 0.9729, 0.9673,\n",
      "        0.9653], dtype=torch.float64) - Recall: tensor([0.9853, 0.9852, 0.9671, 0.9760, 0.9789, 0.9806, 0.9895, 0.9738, 0.9547,\n",
      "        0.9623], dtype=torch.float64) - loss: 0.08428369140625 - \n",
      "Validation Results - Epoch[1] - Accuracy: 0.977 - Precision: tensor([0.9827, 0.9877, 0.9785, 0.9697, 0.9827, 0.9691, 0.9792, 0.9716, 0.9729,\n",
      "        0.9739], dtype=torch.float64) - Recall: tensor([0.9878, 0.9921, 0.9680, 0.9812, 0.9857, 0.9854, 0.9812, 0.9660, 0.9589,\n",
      "        0.9633], dtype=torch.float64) - loss: 0.07670095825195312 - \n",
      "Epoch[2], Iter[1000] Loss: 0.21\n",
      "Epoch[2], Iter[1100] Loss: 0.11\n",
      "Epoch[2], Iter[1200] Loss: 0.13\n",
      "Epoch[2], Iter[1300] Loss: 0.21\n",
      "Epoch[2], Iter[1400] Loss: 0.10\n",
      "Epoch[2], Iter[1500] Loss: 0.10\n",
      "Epoch[2], Iter[1600] Loss: 0.03\n",
      "Epoch[2], Iter[1700] Loss: 0.10\n",
      "Epoch[2], Iter[1800] Loss: 0.11\n",
      "Train Results - Epoch[2] - Accuracy: 0.9827166666666667 - Precision: tensor([0.9886, 0.9792, 0.9707, 0.9873, 0.9863, 0.9915, 0.9793, 0.9784, 0.9837,\n",
      "        0.9840], dtype=torch.float64) - Recall: tensor([0.9922, 0.9939, 0.9857, 0.9781, 0.9841, 0.9729, 0.9936, 0.9848, 0.9684,\n",
      "        0.9709], dtype=torch.float64) - loss: 0.05690661214192708 - \n",
      "Validation Results - Epoch[2] - Accuracy: 0.9827 - Precision: tensor([0.9731, 0.9826, 0.9732, 0.9843, 0.9867, 0.9909, 0.9844, 0.9739, 0.9906,\n",
      "        0.9898], dtype=torch.float64) - Recall: tensor([0.9949, 0.9974, 0.9835, 0.9921, 0.9847, 0.9765, 0.9854, 0.9805, 0.9692,\n",
      "        0.9604], dtype=torch.float64) - loss: 0.054152093505859374 - \n",
      "Epoch[3], Iter[1900] Loss: 0.01\n",
      "Epoch[3], Iter[2000] Loss: 0.04\n",
      "Epoch[3], Iter[2100] Loss: 0.04\n",
      "Epoch[3], Iter[2200] Loss: 0.12\n",
      "Epoch[3], Iter[2300] Loss: 0.04\n",
      "Epoch[3], Iter[2400] Loss: 0.01\n",
      "Epoch[3], Iter[2500] Loss: 0.12\n",
      "Epoch[3], Iter[2600] Loss: 0.17\n",
      "Epoch[3], Iter[2700] Loss: 0.03\n",
      "Epoch[3], Iter[2800] Loss: 0.02\n",
      "Train Results - Epoch[3] - Accuracy: 0.9871333333333333 - Precision: tensor([0.9933, 0.9936, 0.9841, 0.9890, 0.9924, 0.9880, 0.9874, 0.9833, 0.9843,\n",
      "        0.9757], dtype=torch.float64) - Recall: tensor([0.9944, 0.9893, 0.9852, 0.9858, 0.9805, 0.9862, 0.9948, 0.9874, 0.9827,\n",
      "        0.9845], dtype=torch.float64) - loss: 0.0427120849609375 - \n",
      "Validation Results - Epoch[3] - Accuracy: 0.9854 - Precision: tensor([0.9799, 0.9921, 0.9779, 0.9910, 0.9938, 0.9811, 0.9895, 0.9834, 0.9825,\n",
      "        0.9821], dtype=torch.float64) - Recall: tensor([0.9959, 0.9912, 0.9855, 0.9861, 0.9827, 0.9899, 0.9843, 0.9815, 0.9784,\n",
      "        0.9782], dtype=torch.float64) - loss: 0.042832894897460935 - \n",
      "Epoch[4], Iter[2900] Loss: 0.18\n",
      "Epoch[4], Iter[3000] Loss: 0.09\n",
      "Epoch[4], Iter[3100] Loss: 0.11\n",
      "Epoch[4], Iter[3200] Loss: 0.05\n",
      "Epoch[4], Iter[3300] Loss: 0.03\n",
      "Epoch[4], Iter[3400] Loss: 0.04\n",
      "Epoch[4], Iter[3500] Loss: 0.02\n",
      "Epoch[4], Iter[3600] Loss: 0.09\n",
      "Epoch[4], Iter[3700] Loss: 0.03\n",
      "Train Results - Epoch[4] - Accuracy: 0.988 - Precision: tensor([0.9948, 0.9930, 0.9755, 0.9907, 0.9870, 0.9855, 0.9939, 0.9763, 0.9919,\n",
      "        0.9918], dtype=torch.float64) - Recall: tensor([0.9936, 0.9895, 0.9911, 0.9878, 0.9908, 0.9904, 0.9904, 0.9928, 0.9815,\n",
      "        0.9719], dtype=torch.float64) - loss: 0.0403269287109375 - \n",
      "Validation Results - Epoch[4] - Accuracy: 0.9855 - Precision: tensor([0.9849, 0.9921, 0.9724, 0.9853, 0.9839, 0.9844, 0.9968, 0.9704, 0.9907,\n",
      "        0.9959], dtype=torch.float64) - Recall: tensor([0.9959, 0.9921, 0.9884, 0.9921, 0.9929, 0.9899, 0.9760, 0.9874, 0.9795,\n",
      "        0.9604], dtype=torch.float64) - loss: 0.04433556823730469 - \n",
      "Epoch[5], Iter[3800] Loss: 0.00\n",
      "Epoch[5], Iter[3900] Loss: 0.06\n",
      "Epoch[5], Iter[4000] Loss: 0.03\n",
      "Epoch[5], Iter[4100] Loss: 0.16\n",
      "Epoch[5], Iter[4200] Loss: 0.03\n",
      "Epoch[5], Iter[4300] Loss: 0.01\n",
      "Epoch[5], Iter[4400] Loss: 0.09\n",
      "Epoch[5], Iter[4500] Loss: 0.11\n",
      "Epoch[5], Iter[4600] Loss: 0.01\n",
      "Train Results - Epoch[5] - Accuracy: 0.9906833333333334 - Precision: tensor([0.9923, 0.9939, 0.9861, 0.9947, 0.9909, 0.9909, 0.9921, 0.9910, 0.9902,\n",
      "        0.9841], dtype=torch.float64) - Recall: tensor([0.9971, 0.9948, 0.9899, 0.9873, 0.9914, 0.9889, 0.9936, 0.9891, 0.9858,\n",
      "        0.9882], dtype=torch.float64) - loss: 0.032422098795572916 - \n",
      "Validation Results - Epoch[5] - Accuracy: 0.9876 - Precision: tensor([0.9770, 0.9930, 0.9817, 0.9940, 0.9908, 0.9866, 0.9916, 0.9863, 0.9896,\n",
      "        0.9851], dtype=torch.float64) - Recall: tensor([0.9969, 0.9965, 0.9893, 0.9901, 0.9898, 0.9910, 0.9823, 0.9815, 0.9774,\n",
      "        0.9802], dtype=torch.float64) - loss: 0.038075433349609375 - \n",
      "Epoch[6], Iter[4700] Loss: 0.04\n",
      "Epoch[6], Iter[4800] Loss: 0.02\n",
      "Epoch[6], Iter[4900] Loss: 0.02\n",
      "Epoch[6], Iter[5000] Loss: 0.03\n",
      "Epoch[6], Iter[5100] Loss: 0.21\n",
      "Epoch[6], Iter[5200] Loss: 0.11\n",
      "Epoch[6], Iter[5300] Loss: 0.06\n",
      "Epoch[6], Iter[5400] Loss: 0.06\n",
      "Epoch[6], Iter[5500] Loss: 0.06\n",
      "Epoch[6], Iter[5600] Loss: 0.01\n",
      "Train Results - Epoch[6] - Accuracy: 0.9911333333333333 - Precision: tensor([0.9948, 0.9967, 0.9852, 0.9951, 0.9899, 0.9946, 0.9886, 0.9896, 0.9862,\n",
      "        0.9902], dtype=torch.float64) - Recall: tensor([0.9951, 0.9929, 0.9924, 0.9887, 0.9926, 0.9858, 0.9968, 0.9906, 0.9894,\n",
      "        0.9864], dtype=torch.float64) - loss: 0.02971567179361979 - \n",
      "Validation Results - Epoch[6] - Accuracy: 0.9879 - Precision: tensor([0.9859, 0.9938, 0.9827, 0.9901, 0.9918, 0.9855, 0.9906, 0.9807, 0.9856,\n",
      "        0.9919], dtype=torch.float64) - Recall: tensor([0.9969, 0.9956, 0.9884, 0.9881, 0.9878, 0.9899, 0.9864, 0.9864, 0.9836,\n",
      "        0.9752], dtype=torch.float64) - loss: 0.03562294006347656 - \n",
      "Epoch[7], Iter[5700] Loss: 0.03\n",
      "Epoch[7], Iter[5800] Loss: 0.15\n",
      "Epoch[7], Iter[5900] Loss: 0.01\n",
      "Epoch[7], Iter[6000] Loss: 0.12\n",
      "Epoch[7], Iter[6100] Loss: 0.04\n",
      "Epoch[7], Iter[6200] Loss: 0.01\n",
      "Epoch[7], Iter[6300] Loss: 0.02\n",
      "Epoch[7], Iter[6400] Loss: 0.01\n",
      "Epoch[7], Iter[6500] Loss: 0.02\n",
      "Train Results - Epoch[7] - Accuracy: 0.9918166666666667 - Precision: tensor([0.9931, 0.9945, 0.9862, 0.9967, 0.9891, 0.9937, 0.9914, 0.9914, 0.9897,\n",
      "        0.9921], dtype=torch.float64) - Recall: tensor([0.9971, 0.9956, 0.9936, 0.9879, 0.9930, 0.9880, 0.9963, 0.9904, 0.9896,\n",
      "        0.9860], dtype=torch.float64) - loss: 0.027529012044270832 - \n",
      "Validation Results - Epoch[7] - Accuracy: 0.9882 - Precision: tensor([0.9789, 0.9930, 0.9808, 0.9940, 0.9888, 0.9888, 0.9916, 0.9873, 0.9866,\n",
      "        0.9919], dtype=torch.float64) - Recall: tensor([0.9959, 0.9974, 0.9922, 0.9911, 0.9898, 0.9877, 0.9833, 0.9844, 0.9846,\n",
      "        0.9742], dtype=torch.float64) - loss: 0.03526520690917969 - \n",
      "Epoch[8], Iter[6600] Loss: 0.02\n",
      "Epoch[8], Iter[6700] Loss: 0.01\n",
      "Epoch[8], Iter[6800] Loss: 0.01\n",
      "Epoch[8], Iter[6900] Loss: 0.02\n",
      "Epoch[8], Iter[7000] Loss: 0.03\n",
      "Epoch[8], Iter[7100] Loss: 0.02\n",
      "Epoch[8], Iter[7200] Loss: 0.06\n",
      "Epoch[8], Iter[7300] Loss: 0.02\n",
      "Epoch[8], Iter[7400] Loss: 0.10\n",
      "Epoch[8], Iter[7500] Loss: 0.16\n",
      "Train Results - Epoch[8] - Accuracy: 0.9927666666666667 - Precision: tensor([0.9939, 0.9957, 0.9901, 0.9969, 0.9928, 0.9910, 0.9928, 0.9912, 0.9911,\n",
      "        0.9916], dtype=torch.float64) - Recall: tensor([0.9976, 0.9948, 0.9935, 0.9912, 0.9920, 0.9930, 0.9965, 0.9923, 0.9903,\n",
      "        0.9864], dtype=torch.float64) - loss: 0.02526385498046875 - \n",
      "Validation Results - Epoch[8] - Accuracy: 0.9882 - Precision: tensor([0.9790, 0.9930, 0.9865, 0.9940, 0.9918, 0.9823, 0.9937, 0.9835, 0.9876,\n",
      "        0.9899], dtype=torch.float64) - Recall: tensor([0.9969, 0.9974, 0.9903, 0.9881, 0.9878, 0.9933, 0.9823, 0.9854, 0.9846,\n",
      "        0.9752], dtype=torch.float64) - loss: 0.03612041320800781 - \n",
      "Epoch[9], Iter[7600] Loss: 0.04\n",
      "Epoch[9], Iter[7700] Loss: 0.07\n",
      "Epoch[9], Iter[7800] Loss: 0.03\n",
      "Epoch[9], Iter[7900] Loss: 0.12\n",
      "Epoch[9], Iter[8000] Loss: 0.07\n",
      "Epoch[9], Iter[8100] Loss: 0.03\n",
      "Epoch[9], Iter[8200] Loss: 0.01\n",
      "Epoch[9], Iter[8300] Loss: 0.04\n",
      "Epoch[9], Iter[8400] Loss: 0.15\n",
      "Train Results - Epoch[9] - Accuracy: 0.9931333333333333 - Precision: tensor([0.9958, 0.9966, 0.9920, 0.9920, 0.9923, 0.9923, 0.9956, 0.9917, 0.9903,\n",
      "        0.9924], dtype=torch.float64) - Recall: tensor([0.9976, 0.9938, 0.9930, 0.9945, 0.9937, 0.9923, 0.9949, 0.9930, 0.9923,\n",
      "        0.9862], dtype=torch.float64) - loss: 0.0236564453125 - \n",
      "Validation Results - Epoch[9] - Accuracy: 0.9884 - Precision: tensor([0.9849, 0.9930, 0.9874, 0.9843, 0.9908, 0.9844, 0.9936, 0.9883, 0.9857,\n",
      "        0.9909], dtype=torch.float64) - Recall: tensor([0.9969, 0.9938, 0.9884, 0.9941, 0.9919, 0.9899, 0.9781, 0.9844, 0.9918,\n",
      "        0.9742], dtype=torch.float64) - loss: 0.0342026611328125 - \n",
      "Epoch[10], Iter[8500] Loss: 0.01\n",
      "Epoch[10], Iter[8600] Loss: 0.01\n",
      "Epoch[10], Iter[8700] Loss: 0.05\n",
      "Epoch[10], Iter[8800] Loss: 0.04\n",
      "Epoch[10], Iter[8900] Loss: 0.05\n",
      "Epoch[10], Iter[9000] Loss: 0.18\n",
      "Epoch[10], Iter[9100] Loss: 0.34\n",
      "Epoch[10], Iter[9200] Loss: 0.01\n",
      "Epoch[10], Iter[9300] Loss: 0.07\n",
      "Train Results - Epoch[10] - Accuracy: 0.9929833333333333 - Precision: tensor([0.9968, 0.9973, 0.9918, 0.9924, 0.9943, 0.9912, 0.9954, 0.9922, 0.9901,\n",
      "        0.9878], dtype=torch.float64) - Recall: tensor([0.9971, 0.9944, 0.9914, 0.9945, 0.9913, 0.9932, 0.9936, 0.9907, 0.9932,\n",
      "        0.9904], dtype=torch.float64) - loss: 0.02302629191080729 - \n",
      "Validation Results - Epoch[10] - Accuracy: 0.9882 - Precision: tensor([0.9869, 0.9947, 0.9855, 0.9853, 0.9939, 0.9833, 0.9957, 0.9844, 0.9867,\n",
      "        0.9850], dtype=torch.float64) - Recall: tensor([0.9959, 0.9938, 0.9903, 0.9950, 0.9898, 0.9910, 0.9781, 0.9825, 0.9877,\n",
      "        0.9772], dtype=torch.float64) - loss: 0.035357669067382816 - \n",
      "Training has finished successfully!\n"
     ]
    }
   ],
   "source": [
    "# 6 - Definition  of training engine using our custom object\n",
    "training_engine = TrainingEngine(train_dataloader, test_dataloader, model, device)\n",
    "print(\"8. TrainingEngine instantiated.\")\n",
    "\n",
    "training_engine.setup_trainer(optimizer=optimizer, \n",
    "                              criterion=criterion,\n",
    "                              progress_bar=False)\n",
    "print(\"9. Added training function to TrainingEngine.\")\n",
    "\n",
    "training_engine.setup_validation(metrics=[\"Accuracy\", \"Precision\", \"Recall\"])\n",
    "print(\"10. Added metrics to TrainingEngine.\")\n",
    "\n",
    "training_engine.setup_loggers(log_training=True, log_interval=100)\n",
    "print(\"11. Added Loggers to TrainingEngine.\")\n",
    "\n",
    "training_engine.setup_checkpointer(lambda metrics: ((2*metrics['Precision'].mean()*metrics['Recall'].mean())/(metrics['Precision'].mean() + metrics['Recall'].mean())).item())\n",
    "print(\"12. Added Checkpointer to TrainingEngine.\")\n",
    "\n",
    "#training_engine.setup_lr_scheduler_with_warmup(lr_scheduler, warmup_start_value=optimizer_config['lr']/10, warmup_end_value=optimizer_config['lr'], warmup_duration=lr_scheduler_config['warmup_duration'])\n",
    "#print(f\"13. Added learning rate scheduler to TrainingEngine with warmup {'enabled' if lr_scheduler_config['warmup_duration'] else 'disabled'}.\")\n",
    "\n",
    "training_engine.setup_tensorboard()\n",
    "print(\"14. Tensorboard enabled.\")\n",
    "\n",
    "training_engine.run_training(max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "\n",
       "NOTE: Using experimental fast data loading logic. To disable, pass\n",
       "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
       "    https://github.com/tensorflow/tensorboard/issues/4784\n",
       "\n",
       "Address already in use\n",
       "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
       "Contents of stdout:\n",
       "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
       "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tb-logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.Engine at 0x7f9be14a0490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_engine.get_training_engine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
