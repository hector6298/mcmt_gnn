{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "sys.path.insert(1, osp.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hectormejia/opt/anaconda3/envs/mcmt_env/lib/python3.9/site-packages/torch_geometric/typing.py:18: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: dlopen(/Users/hectormejia/opt/anaconda3/envs/mcmt_env/lib/python3.9/site-packages/libpyg.so, 0x0006): Library not loaded: /usr/local/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/Python\n",
      "  Referenced from: <593A788E-3AC3-3D15-B6FD-54CA34BBA4D5> /Users/hectormejia/opt/anaconda3/envs/mcmt_env/lib/python3.9/site-packages/libpyg.so\n",
      "  Reason: tried: '/usr/local/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/Python' (no such file), '/usr/local/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.10/Python' (no such file), '/System/Library/Frameworks/Python.framework/Versions/3.10/Python' (no such file, not in dyld cache)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/Users/hectormejia/opt/anaconda3/envs/mcmt_env/lib/python3.9/site-packages/torch_geometric/typing.py:42: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/hectormejia/opt/anaconda3/envs/mcmt_env/lib/python3.9/site-packages/libpyg.so, 0x0006): Library not loaded: /usr/local/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/Python\n",
      "  Referenced from: <593A788E-3AC3-3D15-B6FD-54CA34BBA4D5> /Users/hectormejia/opt/anaconda3/envs/mcmt_env/lib/python3.9/site-packages/libpyg.so\n",
      "  Reason: tried: '/usr/local/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/Python' (no such file), '/usr/local/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.10/Python' (no such file), '/System/Library/Frameworks/Python.framework/Versions/3.10/Python' (no such file, not in dyld cache)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating graph for S01\n",
      "Processing nodes for camera c002\n",
      "Processing nodes for camera c005\n",
      "Processing nodes for camera c004\n",
      "Processing nodes for camera c003\n",
      "Processing nodes for camera c001\n",
      "Length of node_df 407\n",
      "Processed edges for camera c002. Shapes:  24642 24642 24642 24642\n",
      "Processed edges for camera c005. Shapes:  22466 22466 22466 22466\n",
      "Processed edges for camera c004. Shapes:  12720 12720 12720 12720\n",
      "Processed edges for camera c003. Shapes:  6314 6314 6314 6314\n",
      "Processed edges for camera c001. Shapes:  0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hectormejia/Documents/TFM/mcmt_gnn/torch_dataset/sequence_graph_dataset.py:160: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343686209/work/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  edge_idx = torch.tensor(edge_idx, dtype=torch.int64, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating graph for S03\n",
      "Processing nodes for camera c010\n",
      "Processing nodes for camera c011\n",
      "Processing nodes for camera c014\n",
      "Processing nodes for camera c013\n",
      "Processing nodes for camera c012\n",
      "Processing nodes for camera c015\n",
      "Length of node_df 80\n",
      "Processed edges for camera c010. Shapes:  924 924 924 924\n",
      "Processed edges for camera c011. Shapes:  833 833 833 833\n",
      "Processed edges for camera c014. Shapes:  490 490 490 490\n",
      "Processed edges for camera c013. Shapes:  306 306 306 306\n",
      "Processed edges for camera c012. Shapes:  17 17 17 17\n",
      "Processed edges for camera c015. Shapes:  0 0 0 0\n",
      "Generating graph for S04\n",
      "Processing nodes for camera c033\n",
      "Processing nodes for camera c034\n",
      "Processing nodes for camera c035\n",
      "Processing nodes for camera c032\n",
      "Processing nodes for camera c017\n",
      "Processing nodes for camera c028\n",
      "Processing nodes for camera c021\n",
      "Processing nodes for camera c026\n",
      "Processing nodes for camera c019\n",
      "Processing nodes for camera c027\n",
      "Processing nodes for camera c018\n",
      "Processing nodes for camera c020\n",
      "Processing nodes for camera c016\n",
      "Processing nodes for camera c029\n",
      "Processing nodes for camera c037\n",
      "Processing nodes for camera c030\n",
      "Processing nodes for camera c039\n",
      "Processing nodes for camera c038\n",
      "Processing nodes for camera c031\n",
      "Processing nodes for camera c036\n",
      "Processing nodes for camera c025\n",
      "Processing nodes for camera c022\n",
      "Processing nodes for camera c040\n",
      "Processing nodes for camera c023\n",
      "Processing nodes for camera c024\n",
      "Length of node_df 312\n",
      "Processed edges for camera c033. Shapes:  7436 7436 7436 7436\n",
      "Processed edges for camera c034. Shapes:  5320 5320 5320 5320\n",
      "Processed edges for camera c035. Shapes:  3528 3528 3528 3528\n",
      "Processed edges for camera c032. Shapes:  5060 5060 5060 5060\n",
      "Processed edges for camera c017. Shapes:  1344 1344 1344 1344\n",
      "Processed edges for camera c028. Shapes:  444 444 444 444\n",
      "Processed edges for camera c021. Shapes:  1296 1296 1296 1296\n",
      "Processed edges for camera c026. Shapes:  2060 2060 2060 2060\n",
      "Processed edges for camera c019. Shapes:  1584 1584 1584 1584\n",
      "Processed edges for camera c027. Shapes:  1337 1337 1337 1337\n",
      "Processed edges for camera c018. Shapes:  1288 1288 1288 1288\n",
      "Processed edges for camera c020. Shapes:  1239 1239 1239 1239\n",
      "Processed edges for camera c016. Shapes:  1190 1190 1190 1190\n",
      "Processed edges for camera c029. Shapes:  1449 1449 1449 1449\n",
      "Processed edges for camera c037. Shapes:  2320 2320 2320 2320\n",
      "Processed edges for camera c030. Shapes:  2706 2706 2706 2706\n",
      "Processed edges for camera c039. Shapes:  1526 1526 1526 1526\n",
      "Processed edges for camera c038. Shapes:  1710 1710 1710 1710\n",
      "Processed edges for camera c031. Shapes:  1400 1400 1400 1400\n",
      "Processed edges for camera c036. Shapes:  1029 1029 1029 1029\n",
      "Processed edges for camera c025. Shapes:  418 418 418 418\n",
      "Processed edges for camera c022. Shapes:  217 217 217 217\n",
      "Processed edges for camera c040. Shapes:  234 234 234 234\n",
      "Processed edges for camera c023. Shapes:  81 81 81 81\n",
      "Processed edges for camera c024. Shapes:  0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_dataset.sequence_graph_dataset import SequenceGraphDataset\n",
    "\n",
    "dataset = SequenceGraphDataset(sequence_path_prefix='datasets/AIC20', \n",
    "                               sequence_names=['S01', 'S03', 'S04'], \n",
    "                                annotations_filename='gt.txt')\n",
    "\n",
    "data = dataset[0]     # Access the first processed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_agg_fn': 'sum',\n",
       " 'num_enc_steps': 1,\n",
       " 'num_class_steps': 1,\n",
       " 'reattach_initial_nodes': False,\n",
       " 'reattach_initial_edges': False,\n",
       " 'encoder_feats_dict': {'edges': {'edge_in_dim': 2,\n",
       "   'edge_fc_dims': [4],\n",
       "   'edge_out_dim': 4},\n",
       "  'nodes': {'node_in_dim': 768,\n",
       "   'node_fc_dims': [1024, 512, 128],\n",
       "   'node_out_dim': 32,\n",
       "   'dropout_p': 0.1,\n",
       "   'use_batchnorm': True}},\n",
       " 'edge_model_feats_dict': {'fc_dims': [4],\n",
       "  'dropout_p': 0.1,\n",
       "  'use_batchnorm': True},\n",
       " 'node_model_feats_dict': {'fc_dims': [32],\n",
       "  'dropout_p': 0.1,\n",
       "  'use_batchnorm': True},\n",
       " 'classifier_feats_dict': {'edge_in_dim': 4,\n",
       "  'edge_fc_dims': [],\n",
       "  'edge_out_dim': 1,\n",
       "  'dropout_p': 0,\n",
       "  'use_batchnorm': False,\n",
       "  'is_classifier': True}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.mcmt.rgnn import MOTMPNet\n",
    "import yaml\n",
    "\n",
    "with open(\"config/rgcnn.yml\", \"r\") as config_file:\n",
    "    gnn_arch = yaml.safe_load(config_file)\n",
    "    gnn_arch['classifier_feats_dict']['edge_out_dim'] = 1 \n",
    "gnn_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = MOTMPNet(gnn_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = gnn(data)\n",
    "loss = cross(preds, labels)\n",
    "loss[labels == 0] = loss[labels == 0] /n0\n",
    "loss[labels == 1] = loss[labels == 1] / n1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
